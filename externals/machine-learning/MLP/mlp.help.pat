max v2;#N vpatcher 237 246 867 686;#P user multiSlider 258 54 71 75 0. 1. 2 2681 47;#M frgb 0 0 0;#M brgb 255 255 255;#P user multiSlider 258 227 29 55 0. 1. 1 2681 15;#M frgb 0 0 0;#M brgb 255 255 255;#P comment 144 28 100 196617 train net on current training set (number of epochs;#P comment 144 246 100 196617 sets error tolerance level for termination of training;#P comment 144 203 100 196617 dumps current training set to MAX window;#P comment 144 147 100 196617 dumps current weight values and output slope factors to MAX window;#P comment 144 117 100 196617 toggles internal debugging switch;#P comment 144 73 100 196617 outputs the current output unit activation levels;#P comment 144 357 100 196617 dump net stats to MAX window;#P message 344 352 61 196617 reinitialise;#P message 344 321 93 196617 recognize 0.1 0.1;#P message 344 24 65 196617 graphicsOff;#P message 344 6 61 196617 graphicsOn;#P comment 462 349 100 196617 reinitialise weights to small random values;#P comment 462 318 100 196617 feed forward pass through the network;#P comment 462 5 100 196617 turn graphics display on and off;#P comment 462 388 100 196617 double-click here to see more about weights file format;#N vpatcher 40 55 527 459;#P comment 22 37 125 196617 Format of weights files:;#P comment 21 57 406 196617 The file has a header which indicates how many input and output units are in the net and how many patterns to expect. The file contains weights and bias values which appear in the following order:;#P comment 140 210 100 196617 bias weights for output units;#P comment 140 238 100 196617 output unit slope factors;#P comment 140 182 100 196617 bias weights for hidden units;#P comment 140 154 100 196617 hidden to output connections;#P comment 140 126 100 196617 hidden to hidden connections;#P comment 140 98 100 196617 intput to hidden connections;#P comment 28 272 249 196617 The inter layer connections are ordered as follows:;#P comment 60 360 100 196617 ...;#P comment 60 346 100 196617 input 2 to hidden 2;#P comment 60 317 100 196617 ...;#P comment 60 331 100 196617 input 1 to hidden x;#P comment 60 304 100 196617 input 1 to hidden 2;#P comment 60 290 100 196617 input 1 to hidden 1;#P comment 253 305 172 196617 Other information such as pattern square error and number of epochs will also appear at the end of the file. This information is not used by MAXNet;#P pop;#P newobj 342 388 99 196617 p WeightsFileFormat;#P comment 143 388 100 196617 double-click here to see more about training file format;#P message 43 219 63 196617 dump_train;#P message 43 202 60 196617 dump_test;#P message 43 267 77 196617 get_test_data;#N vpatcher 40 55 530 495;#P comment 29 401 421 196617 Don't forget to set the mu parameter in the info dialog box to set contextual feedback level.;#P comment 29 235 408 196617 MAXNet also has recurrent net capabilities ala Jordan and Elman. To get the feedback to happen \, use extra input units as the context units. Feedback during training and feedforward happens by setting the input value for the context (really an input unit) to be the index of the unit to receive feedback from. Unit indicies are labled from right-to-left \, input-to-hidden-to-output. For example \, if we wanted feedback from the output unit of the xor example above \, we would first need to increase the number of input units to three \, and then set the patterns as:;#P comment 29 49 406 196617 The file has a header which indicates how many input and output units are in the net and how many patterns to expect. The two hidden parameters are not meaningful and were kept there for unexplained reasons. Each training pattern will have #input units + #output units values delimited by white space (tab or space). The xor.tr file has been included here to illustrate a simple example.;#P comment 29 28 161 196617 Format of training pattern files:;#P comment 107 335 100 196617 0.9 0.9 -6 0.1;#P comment 107 347 100 196617 0.1 0.1 -6 0.1;#P comment 107 359 100 196617 0.1 0.9 -6 0.9;#P comment 107 371 100 196617 0.9 0.1 -6 0.9;#P comment 107 119 100 196617 2;#P comment 107 131 100 196617 2;#P comment 107 143 100 196617 1;#P comment 107 155 100 196617 1;#P comment 107 167 100 196617 4;#P comment 107 179 100 196617 0.9 0.9 0.1;#P comment 107 191 100 196617 0.1 0.1 0.1;#P comment 107 203 100 196617 0.1 0.9 0.9;#P comment 107 215 100 196617 0.9 0.1 0.9;#P pop;#P newobj 43 388 101 196617 p TrainingFileFormat;#P message 43 357 40 196617 status;#P message 43 310 103 196617 get_weights xor.wt;#P message 43 73 34 196617 bang;#P message 43 117 37 196617 debug;#P message 43 147 35 196617 dump;#P message 43 246 69 196617 error 0.1;#P message 43 286 125 196617 get_training_data xor.tr;#P newex 258 172 100 196617 mlp 2 2 1 1 xor.wt;#P message 43 28 94 196617 learningRate 0.7 \, momentum 0.9 \, auto_learn 300;#P message 42 334 127 196617 save_weights xor.wt.save;#P comment 172 334 100 196617 save weights to file;#P comment 171 287 100 196617 retreive training set;#P comment 171 310 100 196617 retreive weights file;#P comment 359 172 100 196617 MAXNet - neural net simulator;#P comment 357 213 206 196617 Arguments are: input layer size hidden layer size number of hidden layers output layer size optional weights file to load at instantiation;#P message 344 74 75 196617 xValidateTest;#P message 344 96 78 196617 xValidateTrain;#P comment 458 73 119 196617 generate file that contains network input/output behaviour on test or training data;#P hidden connect 9 0 10 0;#P hidden connect 11 0 10 0;#P hidden connect 12 0 10 0;#P hidden connect 13 0 10 0;#P hidden connect 14 0 10 0;#P hidden connect 15 0 10 0;#P hidden connect 16 0 10 0;#P hidden connect 8 0 10 0;#P hidden connect 17 0 10 0;#P hidden connect 19 0 10 0;#P hidden connect 20 0 10 0;#P hidden connect 21 0 10 0;#P hidden connect 1 0 10 0;#P hidden connect 2 0 10 0;#P hidden connect 28 0 10 0;#P hidden connect 29 0 10 0;#P hidden connect 30 0 10 0;#P hidden connect 31 0 10 0;#P connect 40 0 10 0;#P connect 10 0 39 0;#P pop;